{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "# I am not runing this shells because it will not be able to upload until it is runing phase\n",
    "# Some of the most important functions of Opencv which used in different field of computer vision\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image from give path\n",
    "input=cv2.imread(\"Pictures/Abhishek singh.jpg\")# input=cv2.imread(\"Pictures/Abhishek singh.jpg\",0) for converting grayscale\n",
    "# to display image\n",
    "cv2.imshow(\"Abhishek singh\",input) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"height of image ,\",int(input.shape[0]),'pixels')\n",
    "print(\"wedith of image ,\",int(input.shape[1]),'pixels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the image\n",
    "cv2.imwrite('output.jpg',input)\n",
    "cv2.imwrite('output.png',input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # converting to gray scale image\n",
    "gray_image=cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)# at reading time \n",
    "cv2.imshow(\"grayscale\",gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see its size reduce 2d\n",
    "print(gray_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one more color space is HSV\n",
    "# hue ,Saturation,Value,HSL(they are use color filtering)\n",
    "B,G,R=input[10,50]\n",
    "print(B,G,R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image=cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)# at reading time \n",
    "cv2.imshow(\"HSV image\",hsv_image)\n",
    "cv2.imshow(\"Hue\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"Saturation image\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"value channel\",hsv_image[:,:,2])\n",
    "\n",
    "cv2.waitkey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split image function it in B,G,R\n",
    "B,G,R=cv2.split(input)\n",
    "print (B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow(\"red\",R)\n",
    "cv2.imshow(\"green\",G)\n",
    "cv2.imshow(\"blue\",B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remake image in one color \n",
    "merged=cv2.merge([B,G,R])\n",
    "cv2.imshow(\"merge\",merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amplifythe blur color\n",
    "merge=cv2.merge([B+100,G,R])\n",
    "cv2.imshow(\"megre with blue color\",merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram=cv2.calcHist([input],[0],None,[256],[0,256])\n",
    "\n",
    "plt.hist(input.ravel(),256,[0,256]);plt.show()\n",
    "color=('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histogram2=cv2.calcHist([input],[i],None,[256],[0,256])\n",
    "    plt.plot(histogram2,color=col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing images and shapes using Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.imshow(\"black rectangle\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's draw a line over our black squre\n",
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(image,(0,0),(511,511),(255,127,0),5)\n",
    "cv2.imshow(\"blue line\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## circle\n",
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(image,(350,350),100,(15,75,50),-1)\n",
    "cv2.imshow(\"blue line\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rectangle\n",
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(image,(100,100),(300,250),(127,50,127),5)\n",
    "cv2.imshow(\"blue line\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(image,(100,100),(300,250),(127,50,127),5)\n",
    "cv2.imshow(\"blue line\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text adding in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.zeros((512,512,3),np.uint8)\n",
    "cv2.putText(image.\"hello world\",(75,290),cv2.FONT_HERSHEY_COMPLEX,2,(100,170,0),3)\n",
    "cv2.imshow(\"hello world\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## affine and non affine two types\n",
    "# cv2.warpAffine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "height,width=image.shape[:2]\n",
    "height,width,quarter_width=height/4,width/4\n",
    "T=np.float32([[1,0,quater_width],[0,1,quarter_height]])\n",
    "img_translation=cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow('tranformation',img_translation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cv2.getRotationMatrix2D\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "height,width=image.shape[:2]\n",
    "rotation_matrix=cv2.getRotatioMatrix2D((width/2,height/2),90,1)\n",
    "\n",
    "rotation_matrix=cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow('tranformation',rotation_matrix)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwWndows()\n",
    "## we can do this by transpose for rotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sizing,scaling and interploation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cv2.INTER_AREA,cv2.INTER_NEAREST,cv2.INTER_LINER\n",
    "##cv2.INTER_CUBIC\n",
    "#cv2.INTER_LANZOS4\n",
    "# useding gps tracking\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "#lets make image3/4 of its size\n",
    "image_scaled=cv2.resize(image,None,fx=0.75,fy=0.75)\n",
    "cv2.imshow('scaling-linerI Interpolation',image_scaled)\n",
    "cv2.waitKey(0)\n",
    "# let's double the size of our image\n",
    "\n",
    "image_scaled=cv2.resize(image,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('scaling-cubic interploation',image_scaled)\n",
    "cv2.waitKey(0)\n",
    "## let's resize by setting exact dinesion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE PYRAMIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## useful when images in object detection\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "smaller=cv2.pyrDown(image)## if we wnat numer of images yhen put it into loo.\n",
    "larger=cv2.pyrUp(smaller)\n",
    "cv2.imshow('oridinal',image)\n",
    "cv2.imshow('smaller',smaller)\n",
    "cv2.imshow('larger',larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "height,width=image.shape[:2]\n",
    "# let's get starting pixel coordiantes (top left of cropping rectangle)\n",
    "start_row,start_col=int(height*.25),int(width*.25)\n",
    "# let's get the ending pixel coordinates (bottom right)\n",
    "end_row,end_col=int(height*.75),int(width*.75)\n",
    "#simply use indexing to crop out the rectangler we desire\n",
    "cropped=image[start_row:end_row,start_col:end_col]\n",
    "cv2.imshow(\"original image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"original image\",cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Arithmetic operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this bescally used for allow us to directly add and subtract to the color intensity\n",
    "#increasing and decreasing the brightness\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "m=np.ones(image.shape,dtype=\"uint8\")*75\n",
    "## now add this to our color image\n",
    "added=cv2.add(image,m)\n",
    "cv2.imshow(\"added\",added)\n",
    "## subtracting\n",
    "subt=cv2.subtract(image,m)\n",
    "cv2.imshow(\"subtracted\",subt)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindow()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's see m\n",
    "import numpy as np\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "m=np.ones(image.shape,dtype=\"uint8\")*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## thier are number are more operation   like makeing ellipes ,squre and many more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squre=np.zeros((300,300),np.uints)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-2)\n",
    "cv2.imshow(\"square\",square)\n",
    "cv2.waitKey(0)\n",
    "# ellipse\n",
    "\n",
    "ellipse=np.zeros((300,300),np.uints)\n",
    "cv2.rectangle(ellipse,(150,150),30,0,180,255,-1)\n",
    "cv2.imshow(\"square\",ellipse)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And=cv2.bitwise_and(square,ellipse)\n",
    "cv2.imshow(\"and\",And)\n",
    "cv2.waitKey(0)\n",
    "## As the same way we can do more like OR ,NOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blurring is operation where we average the pixels within a region\n",
    "\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "kernel_3x3=np.ones((3,3),np.float32)/9\n",
    "# cv2.fillter2D is apply\n",
    "blurred=cv2.filter2D(image,-1,kernel_3x3)\n",
    "cv2.imshow(\"3x3 kernal blurring\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindo\n",
    "\n",
    "## 7x7\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "kernel_7x7=np.ones((7,7),np.float32)/49\n",
    "# cv2.fillter2D is apply\n",
    "blurred=cv2.filter2D(image,-1,kernel_7x7)\n",
    "cv2.imshow(\"7x7 kernal blurring\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindow()\n",
    "## their are some more type of blurring are present in cv2 read doumantitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image De-noising ,Non-Local means denoising(for clean image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it has the effect of in  strengthening or emphasizing adges in an image\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "cv2.imshow('original',image)\n",
    "## creating shapening kernal ,do't normalize \n",
    "kernal_sharpening=np.array([[-1,-1,-1],\n",
    "                           [-1,9,-1]\n",
    "                           [-1,-1,-1]])\n",
    "#applying different kernal to the input image\n",
    "sharpened=cv2.filter2D(image,-1,kernal_sharpening)\n",
    "cv2.imshow(\"Image sharpening\",sharpened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindow()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding,Binarization and Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## thresholding is act of converting an image to a binary form\n",
    "##cv2.thershold(image,thresholdvalue,maxvalue,threshold type)\n",
    "## most imortant when applaying it cinvert image into grayscale,i did that \n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "cv2.imshow('original',image)\n",
    "## values below 127 going to black above 255  is white\n",
    "ret,thresh1=cv2.threshold(image,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 threshold binary inverse',thresh1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adaptive thrashold is better\n",
    "image=cv2.GaussianBlur(image,(3,3),0)\n",
    "thres=cv2.adaptiveThreshold(image,259,cv2.ADAPTIVE_THRESH_MEAN_C,CV2.THRESH_BINARY,3,5)\n",
    "cv2.imshow(\"otus's threshold\",thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation and Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dilation-add pixels to the boundries of object in an image\n",
    "## erosion-removes pixels at the boundries of object in an image\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "erosion =cv2.erode(image,kernel,iterations=1)\n",
    "cv2.imshow('erosion',erosion)\n",
    "cv2.waitKey(0)\n",
    "#\n",
    "dilation=cv2.dilate(image,kernel,iteration=1)\n",
    "cv2.imshow('dilation',dilation)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection and Image gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they very important operation in object detection\n",
    "# Sobel,laplacian,canny they are algorithm used in edge detection\n",
    "image=cv2.imread(\"Pictures/Abhishek singh.jpg\")\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "height,width=image.shape\n",
    "# extract sobel edges\n",
    "sobel_x=cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_Y=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5)\n",
    "cv2.imshow('sobel_x',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('sobel_Y',sobel_Y)\n",
    "cv2.waitKey(0)\n",
    "sobel_OR=cv2.bitwise_or(sobel_x,sobel_Y)\n",
    "cv2.imshow('sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
